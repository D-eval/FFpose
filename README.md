# Forward-Forward Poses Classification

损失函数不是通过反向传播得到的梯度来更新参数，而是通过直接在网络中进行正向传播时调整网络的激活输出。

假设某一层的好度函数是该层经过修正线性单元（rectified linear neurons）的活动值的平方和。学习的目标是使真实数据的好度高于某个阈值，而负数据的好度低于该阈值。更具体地，目标是正确分类输入向量为正数据或负数据，其中输入向量为正的概率（即真实数据）由如下逻辑函数给出：

$$ p(positive) = \sigma (\sum_j y_j^2 - \theta) $$

其中，$y_j$是隐藏单元 $j$ 在层归一化前的活动值，$\sigma$是logistic函数，$\theta$ 是阈值。负数据可以通过神经网络的自上而下连接来预测，或者可以外部提供。

归一化移除了所有用于确定第一隐藏层goodness的activity信息，迫使下一层隐藏层使用第一层神经元活动的相对信息。相对活动在进行层归一化后不会受到影响。换句话说，第一层隐藏层的活动向量有长度和方向。长度用于定义该层的好度，而只有方向信息被传递到下一层。

## 思路

用一个人为的方式判断「走路」，作为先验信息，得到

## 讲解

每个批次加载姿态序列`BTNd`和`text`

每一个隐层只负责一个类的拉拢，而排斥其他类，作为goodness函数

先embed每个骨骼并加入`time_embedding`，得到`(B,T,N,D)`



这一层的goodness函数，选取

用spacial attention得到# FFpose
